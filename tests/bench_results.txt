tests run on a haswell node (64 cores, exclusive reservation)
we use the MKL as our BLAS of choice
we use the minimum of several runs as its the best representation of the actual computing time (noise is additive)

-------------------- DOUBLE --------------------

BLAS (min of 3 runs)
toy: 3ms
small: 7ms
medium: 4ms
large: 4975ms
realistic: 4886ms

BLAS no atomic reduction (min of 3 runs)
toy: 3ms
small: 12ms
medium: 1ms
large: 4812ms
realistic: 4713ms
=> barely faster, the synchronisation on reduction is NOT a bottleneck

BLAS explicit transpose (min of 3 runs)
toy: 2ms
small: 20ms
medium: 3ms
large: 4891ms
realistic: 4789ms
=> very small improvements, not worth it

No BLAS (min of 5 runs)
toy: 0ms
small: 0ms
medium: 9ms
large: 5867ms
realistic: 5794ms
=> about 20% slower than BLAS

Old Kronmult (min of 5 runs)
toy: 0ms
small: 0ms
medium: 5ms
large: 8688ms
realistic: 8623ms
=> speed similar to old no-blas version

-------------------- FLOAT --------------------

BLAS (min of 3 runs)
toy: 3ms
small: 7ms
medium: 7ms
large: 2570ms
realistic: 2531ms

No BLAS (min of 3 runs)
toy: 0ms
small: 0ms
medium: 5ms
large: 3969ms
realistic: 3874ms

Old Kronmult (min of 3 runs)
toy: 0ms
small: 0ms
medium: 6ms
large: 7352ms
realistic: 7342ms

-------------------- GPU DOUBLE --------------------

gpu_thread (min of 3 runs)
too long to measure

gpu_inputsize (min of 3 runs)
Results:
toy: 1ms
small: 2ms
medium: 4ms
large: 3796ms
realistic: 3638ms
